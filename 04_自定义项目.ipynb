{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f8e2ff52-d93e-4202-8330-b473533ee6f4",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 现在我们基本了解了bedrock的sdk, knowledge base和langchain集成的接口。现在我们进行一个实践项目"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18a5527c",
   "metadata": {},
   "source": [
    "## 前言"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d722e7f",
   "metadata": {},
   "source": [
    "如今很多交易所要求上市公司出了财报以外，还需提交ESG报告，披露公司在环境、社会和公司治理等方面信息，ESG报告的撰写是高度专业性工作，内容广泛，要求复杂。而生成式AI的发展，很大程度上可以简化ESG报告的撰写。利用 RAG 技术，结合企业私有ESG等数据，基于 LLM 和智能搜索，以低代码/无代码的形式，简单快速地构建企业私域知识库，配合提示词工程，可为企业提供高质量的写作建议，甚至生成报告。接下来我们让我们一起体验Bedrock Knowledge Base和Claude3如何帮助公司生成ESG报告。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1499dddc",
   "metadata": {},
   "source": [
    "## Bedrock Knowledge Base 检索ESG报告相关内容"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c3d7d41",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "from botocore.auth import SigV4Auth\n",
    "from botocore.awsrequest import AWSRequest\n",
    "from requests_aws4auth import AWS4Auth\n",
    "import botocore.session\n",
    "from langchain.chains.llm import LLMChain\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_community.chat_models import BedrockChat\n",
    "\n",
    "question = 'ZTO Express Water Management'\n",
    "\n",
    "# 1. set up bedrock knowledge base client and retrieve\n",
    "kb_client = boto3.client('bedrock-agent-runtime')\n",
    "kb_response = kb_client.retrieve(\n",
    "    knowledgeBaseId='your-bedrock-konwledgebase-id',\n",
    "    retrievalQuery={\n",
    "        'text': question\n",
    "    },\n",
    "    retrievalConfiguration={\n",
    "        'vectorSearchConfiguration': {\n",
    "            'numberOfResults': 10,\n",
    "            'overrideSearchType': 'HYBRID'\n",
    "        }\n",
    "    }\n",
    "    #nextToken='string'\n",
    ")\n",
    "context = \"\"\n",
    "for result in kb_response['retrievalResults']:\n",
    "    context = context +'\\n'+ result['content']['text']\n",
    "    print(result['location'])\n",
    "    print(result['content']['text'])\n",
    "    print(\"----------------\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7363d46a",
   "metadata": {},
   "source": [
    "## Claude3 基于检索到的文本生成回答"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cb55770",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# 2. set up llm - claude3\n",
    "claude3_kwargs = {\n",
    "    \"temperature\":0.0001,\n",
    "    #\"temperature\":1,\n",
    "    \"top_k\":250,\n",
    "    \"top_p\":0.999,\n",
    "    \"max_tokens\": 3000,\n",
    "}\n",
    "claude3 = BedrockChat(\n",
    "    model_id=\"anthropic.claude-3-sonnet-20240229-v1:0\",\n",
    "    model_kwargs=claude3_kwargs\n",
    ")\n",
    "prompt_template = \"\"\"Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
    "\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "Helpful Answer:\"\"\"\n",
    "prompt = PromptTemplate(\n",
    "    template=prompt_template, input_variables=[\"context\", \"question\"]\n",
    ")\n",
    "\n",
    "chain_01 = LLMChain(llm=claude3, prompt=prompt)\n",
    "\n",
    "response_01=chain_01.invoke({'question': question,'context': context})\n",
    "print(response_01['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e3e2f46",
   "metadata": {},
   "source": [
    "## Claude3 针对某个ESG议题生成报告"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05b70c0d",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "prompt_template_02 = \"\"\"\n",
    "你是撰写ESG（环境、社会和治理）报告的专家。\n",
    "\n",
    "本次,我们需要您为一家{industry}行业的公司,就 GRI 重要性议题\"{topic}\"编写 ESG 报告内容。\n",
    "\n",
    "公司提供的相关数据:\n",
    "{statistics}\n",
    "\n",
    "此外,您将参考其他公司的 ESG 信息:\n",
    "{relevant_info}\n",
    "\n",
    "报告内容要求:\n",
    "1. 字数在 5000 字以上\n",
    "2. 遵循 GRI 标准框架的要求\n",
    "3. 阐述公司在该议题下的管理政策、具体行动及未来规划\n",
    "4. 根据数据给出一些详细的实际案例\n",
    "5. 报告结构合理,行文条理清晰,信息连贯一致\n",
    "\n",
    "请按照上述要求,为我们撰写高质量的 ESG 报告内容。\n",
    "\"\"\"\n",
    "\n",
    "prompt_02 = PromptTemplate(\n",
    "    template=prompt_template_02, input_variables=[\"industry\",\"topic\",\"statistics\",\"relevant_info\"]\n",
    ")\n",
    "\n",
    "claude3_kwargs = {\n",
    "    #\"temperature\":0.0001,\n",
    "    \"temperature\":1,\n",
    "    \"top_k\":250,\n",
    "    \"top_p\":1,\n",
    "    \"max_tokens\": 3000,\n",
    "}\n",
    "claude3 = BedrockChat(\n",
    "    model_id=\"anthropic.claude-3-sonnet-20240229-v1:0\",\n",
    "    model_kwargs=claude3_kwargs\n",
    ")\n",
    "chain_02 = LLMChain(llm=claude3, prompt=prompt_02, verbose=True)\n",
    "\n",
    "result = chain_02.invoke({\n",
    "    \"industry\": \"物流\",\n",
    "    \"topic\": \"水资源和污水\",\n",
    "    \"statistics\":'''2022年废水排放量为 2,00.00 万 m3，废水排放强度为 2.22m3/ 万元，中水回用量为 66.66 万 m3。''',\n",
    "    \"relevant_info\": response_01['text']\n",
    "})\n",
    "\n",
    "print(result['text'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p310",
   "language": "python",
   "name": "conda_pytorch_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
