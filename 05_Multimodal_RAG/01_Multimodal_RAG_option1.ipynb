{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3762846",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "! pip install -U langchain chromadb langchain-experimental # (newest versions required for multi-modal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "877cef0c",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# lock to 0.10.19 due to a persistent bug in more recent versions\n",
    "! pip install \"unstructured[all-docs]==0.10.19\" pillow pydantic lxml pillow matplotlib tiktoken open_clip_torch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eec51220-6a25-451d-a5c7-0569b92794b9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "! pip install -q langchain_community"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4cd022a",
   "metadata": {},
   "source": [
    "For unstructured, you will also need poppler (https://pdf2image.readthedocs.io/en/latest/installation.html) and tesseract (https://tesseract-ocr.github.io/tessdoc/Installation.html) in your system.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d4efc48-e091-4784-bf11-d599ed889985",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "! pip install pdf2image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14a7cff5-ed44-4087-b24b-1cdd6b7d2921",
   "metadata": {},
   "source": [
    "## 0. PDF转图片处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e32f3750-11b4-4aaa-8ccb-9edcecc6279e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pypdfium2 as pdfium\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from io import BytesIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23fd857f-3a1f-4862-93e7-8024e2b00a47",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_pdf_to_images(file_path, scale=300/72):\n",
    "    \n",
    "    pdf_file = pdfium.PdfDocument(file_path)  \n",
    "    page_indices = [i for i in range(len(pdf_file))]\n",
    "    \n",
    "    renderer = pdf_file.render(\n",
    "        pdfium.PdfBitmap.to_pil,\n",
    "        page_indices = page_indices, \n",
    "        scale = scale,\n",
    "    )\n",
    "    \n",
    "    list_final_images = [] \n",
    "    \n",
    "    for i, image in zip(page_indices, renderer):\n",
    "        \n",
    "        image_byte_array = BytesIO()\n",
    "        image.save(image_byte_array, format='jpeg', optimize=True)\n",
    "        image_byte_array = image_byte_array.getvalue()\n",
    "        list_final_images.append(dict({i:image_byte_array}))\n",
    "    \n",
    "    return list_final_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d498c8ee-ae4d-4f01-9ed9-987aa56e2695",
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_pdf_to_images = convert_pdf_to_images('x1-mini-g4-user-manual-en.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a001062-1c89-49db-be91-6d3d5f9d3d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_images(list_dict_final_images):\n",
    "    \n",
    "    all_images = [list(data.values())[0] for data in list_dict_final_images]\n",
    "\n",
    "    for index, image_bytes in enumerate(all_images):\n",
    "\n",
    "        image = Image.open(BytesIO(image_bytes))\n",
    "        image.save(f'/home/ec2-user/SageMaker/files/images/{index}.jpg') # 路经修改！！！！！！！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd46c9fc-f891-4bc9-8674-1fd2ace493b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_images(convert_pdf_to_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18128aea",
   "metadata": {},
   "source": [
    "# 1. Data Loading"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "188f4aee",
   "metadata": {},
   "source": [
    "## Partition PDF text and images\n",
    "use partition_pdf below from Unstructured to extract text and images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "384756d2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Folder with pdf and extracted images 路经修改！！！！！！！\n",
    "path = \"/home/ec2-user/SageMaker/files/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dd4af90",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Extract images, tables, and chunk text\n",
    "import pytesseract\n",
    "from unstructured.partition.pdf import partition_pdf\n",
    "\n",
    "raw_pdf_elements = partition_pdf(\n",
    "    filename=path + \"user-guide.pdf\",\n",
    "    extract_images_in_pdf=False,\n",
    "    infer_table_structure=True,\n",
    "    chunking_strategy=\"by_title\",\n",
    "    max_characters=4000,\n",
    "    new_after_n_chars=3800,\n",
    "    combine_text_under_n_chars=2000,\n",
    "    image_output_dir_path=path,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a1d1c4a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Categorize text elements by type\n",
    "tables = []\n",
    "texts = []\n",
    "for element in raw_pdf_elements:\n",
    "    if \"unstructured.documents.elements.Table\" in str(type(element)):\n",
    "        tables.append(str(element))\n",
    "    elif \"unstructured.documents.elements.CompositeElement\" in str(type(element)):\n",
    "        texts.append(str(element))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02887a07-1d68-4a8a-9479-c9f3a3d459ff",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9c52ce5",
   "metadata": {},
   "source": [
    "# 2. Multi-modal embeddings with our document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59653016",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import uuid\n",
    "\n",
    "import chromadb\n",
    "import numpy as np\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_experimental.open_clip import OpenCLIPEmbeddings\n",
    "from PIL import Image as _PILImage\n",
    "\n",
    "# Create chroma\n",
    "vectorstore = Chroma(\n",
    "    collection_name=\"mm_rag_clip_photos\", embedding_function=OpenCLIPEmbeddings()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c63f76c9-5a0f-43e5-8d60-e3ad65530d2f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get image URIs with .jpg extension only 步骤0的存图片的路径！！！！！！！\n",
    "path = \"/home/ec2-user/SageMaker/files/images\"\n",
    "image_uris = sorted(\n",
    "    [\n",
    "        os.path.join(path, image_name)\n",
    "        for image_name in os.listdir(path)\n",
    "        if image_name.endswith(\".jpg\")\n",
    "    ]\n",
    ")\n",
    "print(image_uris)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9865cc77-d251-4559-bf9f-a20be21860b9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Add images\n",
    "vectorstore.add_images(uris=image_uris)\n",
    "\n",
    "# Add documents\n",
    "vectorstore.add_texts(texts=texts)\n",
    "\n",
    "# Make retriever\n",
    "retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b3bd98d",
   "metadata": {},
   "source": [
    "# 3. RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eb8f9b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "import io\n",
    "from io import BytesIO\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "def resize_base64_image(base64_string, size=(128, 128)):\n",
    "    \"\"\"\n",
    "    Resize an image encoded as a Base64 string.\n",
    "\n",
    "    Args:\n",
    "    base64_string (str): Base64 string of the original image.\n",
    "    size (tuple): Desired size of the image as (width, height).\n",
    "\n",
    "    Returns:\n",
    "    str: Base64 string of the resized image.\n",
    "    \"\"\"\n",
    "    # Decode the Base64 string\n",
    "    img_data = base64.b64decode(base64_string)\n",
    "    img = Image.open(io.BytesIO(img_data))\n",
    "\n",
    "    # Resize the image\n",
    "    resized_img = img.resize(size, Image.LANCZOS)\n",
    "\n",
    "    # Save the resized image to a bytes buffer\n",
    "    buffered = io.BytesIO()\n",
    "    resized_img.save(buffered, format=img.format)\n",
    "\n",
    "    # Encode the resized image to Base64\n",
    "    return base64.b64encode(buffered.getvalue()).decode(\"utf-8\")\n",
    "\n",
    "\n",
    "def is_base64(s):\n",
    "    \"\"\"Check if a string is Base64 encoded\"\"\"\n",
    "    try:\n",
    "        return base64.b64encode(base64.b64decode(s)) == s.encode()\n",
    "    except Exception:\n",
    "        return False\n",
    "\n",
    "\n",
    "def split_image_text_types(docs):\n",
    "    \"\"\"Split numpy array images and texts\"\"\"\n",
    "    images = []\n",
    "    text = []\n",
    "    for doc in docs:\n",
    "        doc = doc.page_content  # Extract Document contents\n",
    "        if is_base64(doc):\n",
    "            # Resize image to avoid OAI server error\n",
    "            images.append(\n",
    "                resize_base64_image(doc, size=(250, 250))\n",
    "            )  # base64 encoded str\n",
    "        else:\n",
    "            text.append(doc)\n",
    "    return {\"images\": images, \"texts\": text}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60d23f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnableLambda, RunnablePassthrough\n",
    "# from langchain_openai import ChatOpenAI\n",
    "from langchain_community.chat_models import BedrockChat\n",
    "\n",
    "\n",
    "def prompt_func(data_dict):\n",
    "    # Joining the context texts into a single string\n",
    "    formatted_texts = \"\\n\".join(data_dict[\"context\"][\"texts\"])\n",
    "    messages = []\n",
    "\n",
    "    # Adding image(s) to the messages if present\n",
    "    if data_dict[\"context\"][\"images\"]:\n",
    "        for img in data_dict[\"context\"][\"images\"]:\n",
    "            image_message = {\n",
    "                \"type\": \"image\",\n",
    "                \"source\": {\n",
    "                    \"type\": \"base64\",\n",
    "                    \"media_type\": \"image/jpeg\",\n",
    "                    \"data\": img\n",
    "                    #\"data\": data_dict['context']['images'][0]\n",
    "                },\n",
    "            }\n",
    "            messages.append(image_message)\n",
    "\n",
    "    text_message = {\n",
    "        \"type\": \"text\",\n",
    "        \"text\": (\n",
    "            \"As an expert in photovoltaic inverter systems, your task is to analyze and and interpret technical images,\"\n",
    "            \"considering their meanings. Some images may not be relevant to the question and just ignore the irrelevant info.\\n \"\n",
    "            \"Alongside the images, you will be \"\n",
    "            \"provided with related text to offer context. Both will be retrieved from a vectorstore based \"\n",
    "            \"on user-input keywords. Please use your extensive knowledge and analytical skills to provide a \"\n",
    "            \"comprehensive summary that includes:\\n\"\n",
    "            \"- A detailed description of the visual elements in the image.\\n\"\n",
    "            \"- The symbols and operational parameters of the image.\\n\"\n",
    "            \"- An interpretation of the image's operation stepes.\\n\"\n",
    "            \"- Connections between the image and the related text.\\n\\n\"\n",
    "            \"- output in Chinese\"\n",
    "            f\"User-provided keywords: {data_dict['question']}\\n\\n\"\n",
    "            \"Text and / or tables:\\n\"\n",
    "            f\"{formatted_texts}\"\n",
    "        ),\n",
    "    }\n",
    "    messages.append(text_message)\n",
    "\n",
    "    return [HumanMessage(content=messages)]\n",
    "\n",
    "model = BedrockChat(model_id=\"anthropic.claude-3-sonnet-20240229-v1:0\",model_kwargs={\"temperature\": 0, \"max_tokens\": 1024})\n",
    "#model = ChatOpenAI(temperature=0, model=\"gpt-4-vision-preview\", max_tokens=1024)\n",
    "\n",
    "# RAG pipeline\n",
    "chain = (\n",
    "    {\n",
    "        \"context\": retriever | RunnableLambda(split_image_text_types),\n",
    "        \"question\": RunnablePassthrough(),\n",
    "    }\n",
    "    | RunnableLambda(prompt_func)\n",
    "    | model\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb889d4c",
   "metadata": {},
   "source": [
    "# 4. Test retrieval and run RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b23a27d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML, display\n",
    "\n",
    "\n",
    "def plt_img_base64(img_base64):\n",
    "    # Create an HTML img tag with the base64 string as the source\n",
    "    image_html = f'<img src=\"data:image/jpeg;base64,{img_base64}\" />'\n",
    "\n",
    "    # Display the image by rendering the HTML\n",
    "    display(HTML(image_html))\n",
    "\n",
    "\n",
    "docs = retriever.get_relevant_documents(\"LCD Operation\", k=5)\n",
    "for doc in docs:\n",
    "    if is_base64(doc.page_content):\n",
    "        plt_img_base64(doc.page_content)\n",
    "    else:\n",
    "        print(doc.page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90191f6b-b1e1-490b-bbe0-b4777e532f7e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "chain.invoke(\"LCD Operation\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p310",
   "language": "python",
   "name": "conda_pytorch_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
